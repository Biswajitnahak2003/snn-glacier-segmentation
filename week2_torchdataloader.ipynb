{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93c2a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95689362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports and helper function are ready.\n"
     ]
    }
   ],
   "source": [
    "# This is the function we built in Week 1. We'll use it again.\n",
    "def load_and_stack_by_id(base_path, label_filename):\n",
    "    \"\"\"Loads a single 5-band image and its mask.\"\"\"\n",
    "    try:\n",
    "        identifier = f\"_{os.path.basename(label_filename).split('_')[-2]}_{os.path.basename(label_filename).split('_')[-1]}\"\n",
    "    except IndexError:\n",
    "        return None, None\n",
    "\n",
    "    band_folders = ['Band1', 'Band2', 'Band3', 'Band4', 'Band5']\n",
    "    layer_paths = [glob.glob(os.path.join(base_path, f, f'*{identifier}'))[0] for f in band_folders]\n",
    "    \n",
    "    image_layers = [rasterio.open(path).read(1) for path in layer_paths]\n",
    "    stacked_image = np.stack(image_layers, axis=0)\n",
    "    \n",
    "    mask_path = os.path.join(base_path, 'label', label_filename)\n",
    "    with rasterio.open(mask_path) as src:\n",
    "        mask = src.read(1)\n",
    "        \n",
    "    return stacked_image, mask\n",
    "\n",
    "print(\"Imports and helper function are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29809972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlacierDataset class is defined.\n"
     ]
    }
   ],
   "source": [
    "# Creating the Custom GlacierDataset Class ---\n",
    "\n",
    "class GlacierDataset(Dataset):\n",
    "    def __init__(self, base_path, image_ids):\n",
    "        \"\"\"\n",
    "        This is the constructor. It runs only once when we create the dataset.\n",
    "        It sets up the list of files to use.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.base_path = base_path\n",
    "        self.image_ids = image_ids # This will be a list of label filenames\n",
    "        print(f\"Dataset created with {len(self.image_ids)} samples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        This method simply returns the total number of samples in the dataset.\n",
    "        PyTorch uses this to know how big the dataset is.\n",
    "        \"\"\"\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        This is the most important method. PyTorch calls this to get a SINGLE sample.\n",
    "        'idx' is the index of the sample to fetch (e.g., 0 for the first sample).\n",
    "        \"\"\"\n",
    "        # Get the filename for the requested sample\n",
    "        label_filename = self.image_ids[idx]\n",
    "        \n",
    "        # Use our helper function to load the image and mask\n",
    "        image, mask = load_and_stack_by_id(self.base_path, label_filename)\n",
    "        \n",
    "        # Convert the NumPy arrays to PyTorch Tensors\n",
    "        # We also change the data type to float, which is what neural networks expect.\n",
    "        image_tensor = torch.from_numpy(image.astype(np.float32))\n",
    "        mask_tensor = torch.from_numpy(mask.astype(np.float32)).unsqueeze(0)\n",
    "        return image_tensor, mask_tensor\n",
    "\n",
    "print(\"GlacierDataset class is defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "566a274a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 20 samples.\n",
      "Dataset created with 5 samples.\n",
      "DataLoaders are ready.\n"
     ]
    }
   ],
   "source": [
    "# Split Data and Create DataLoaders ---\n",
    "\n",
    "TRAIN_DATA_PATH = 'D:/GlacierHack_practice/train'\n",
    "\n",
    "# Get all 25 label filenames\n",
    "all_label_filenames = sorted(os.listdir(os.path.join(TRAIN_DATA_PATH, 'label')))\n",
    "\n",
    "# Simple 80/20 split: 20 for training, 5 for validation\n",
    "train_ids = all_label_filenames[:20]\n",
    "val_ids = all_label_filenames[20:]\n",
    "\n",
    "# Create an instance of our dataset for training\n",
    "train_dataset = GlacierDataset(base_path=TRAIN_DATA_PATH, image_ids=train_ids)\n",
    "\n",
    "# Create an instance for validation\n",
    "val_dataset = GlacierDataset(base_path=TRAIN_DATA_PATH, image_ids=val_ids)\n",
    "\n",
    "# Now, create the DataLoaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "print(\"DataLoaders are ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7503d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Verifying the DataLoader ---\n",
      "Shape of one batch of images: torch.Size([4, 5, 512, 512])\n",
      "Shape of one batch of masks: torch.Size([4, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# Verify the DataLoader ---\n",
    "\n",
    "print(\"\\n--- Verifying the DataLoader ---\")\n",
    "# 'next(iter(loader))' is how you get one batch of data\n",
    "images_batch, masks_batch = next(iter(train_loader))\n",
    "\n",
    "# Let's check the shape. It should be (batch_size, channels, height, width)\n",
    "print(f\"Shape of one batch of images: {images_batch.shape}\")\n",
    "print(f\"Shape of one batch of masks: {masks_batch.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-base-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
