{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ0XnJYxj165",
        "outputId": "5240b11f-2520-4c52-d5dc-268f96915065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "## mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wmpDVDhkj_6T",
        "outputId": "38e3e8f4-f4ea-4c9d-d3ee-9e662e36e010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: snntorch in /usr/local/lib/python3.12/dist-packages (0.9.4)\n",
            "Requirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.12/dist-packages (0.5.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (11.3.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.7.0)\n",
            "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (1.0.22)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (0.24.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from segmentation-models-pytorch) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8->segmentation-models-pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install snntorch segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhZKMwpdOApJ",
        "outputId": "9299cebb-4c43-4e24-c49f-e4fa47571f8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è≥ Initializing ResNet50 SNN (Big Boss Mode)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2521682462.py:284: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "SNN Ep 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.27s/it, loss=1.42]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.0011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:20<00:00,  2.06s/it, loss=1.39]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.0221\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:20<00:00,  2.09s/it, loss=1.37]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.0580\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:20<00:00,  2.10s/it, loss=1.28]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.1050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.17s/it, loss=1.27]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.2004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.13s/it, loss=1.17]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.2941\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.19s/it, loss=1.04]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.3136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.20s/it, loss=0.993]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.3132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.18s/it, loss=1.01]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.3250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.22s/it, loss=1.02]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.3333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.21s/it, loss=1.03]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.3500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.20s/it, loss=0.9]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.3878\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.21s/it, loss=1.02]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.3564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.21s/it, loss=0.943]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.3880\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.18s/it, loss=0.96]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.2426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.18s/it, loss=0.846]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.18s/it, loss=0.941]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.19s/it, loss=0.835]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.2079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.19s/it, loss=1.13]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.3731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.18s/it, loss=0.96]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 21: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.23s/it, loss=0.909]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.3886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.21s/it, loss=0.934]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.3812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 23: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.24s/it, loss=0.889]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.3695\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 24: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.19s/it, loss=0.789]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 25: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.21s/it, loss=0.793]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4449\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 26: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.18s/it, loss=0.807]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4212\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 27: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.23s/it, loss=0.945]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 28: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.26s/it, loss=0.807]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.3783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 29: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.19s/it, loss=0.8]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4599\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.30s/it, loss=0.684]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 31: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:23<00:00,  2.36s/it, loss=0.783]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 32: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:23<00:00,  2.32s/it, loss=0.843]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 33: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.20s/it, loss=0.83]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4189\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 34: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.21s/it, loss=0.754]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4610\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 35: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.20s/it, loss=0.715]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.3825\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 36: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.19s/it, loss=0.867]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 37: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.18s/it, loss=0.739]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 38: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.19s/it, loss=0.852]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4247\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 39: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.19s/it, loss=0.724]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 40: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.19s/it, loss=0.675]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 41: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:21<00:00,  2.19s/it, loss=0.697]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 42: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.29s/it, loss=0.698]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 43: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.23s/it, loss=0.964]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4242\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 44: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.21s/it, loss=0.783]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "SNN Ep 45: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:22<00:00,  2.21s/it, loss=0.634]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ‚úÖ Val MCC: 0.4071\n",
            "üèÅ SNN Finished. Best MCC: 0.4731\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "from torchvision import models\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from snntorch import utils\n",
        "import gc\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION (BOSS MODE)\n",
        "# ==========================================\n",
        "CONFIG = {\n",
        "    \"base_dir\": \"/content/drive/MyDrive/GlacierHack_practice/Train\",\n",
        "    \"project_dir\": \"/content/drive/MyDrive/Glacier_SNN_ResNet50\",\n",
        "\n",
        "    \"model_type\": \"SNN\",\n",
        "\n",
        "    # PARAMS\n",
        "    \"time_steps\": 6,\n",
        "    \"batch_size\": 2,       \n",
        "    \"lr\": 1e-4,\n",
        "    \"epochs\": 45,\n",
        "    \"beta\": 0.9,\n",
        "    \"threshold\": 0.25,\n",
        "    \"slope\": 25,          \n",
        "\n",
        "    \"num_workers\": 2,\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "os.makedirs(CONFIG['project_dir'], exist_ok=True)\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# ==========================================\n",
        "# 2. DATASET\n",
        "# ==========================================\n",
        "class GlacierDataset(Dataset):\n",
        "    def __init__(self, base_dir, transform=None):\n",
        "        self.base_dir = Path(base_dir)\n",
        "        self.band_dirs = [self.base_dir / f\"Band{i}\" for i in range(1, 6)]\n",
        "        self.label_dir = self.base_dir / \"labels\"\n",
        "        self.ids = sorted([p.stem for p in self.band_dirs[0].glob(\"*.tif\")])\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.ids[idx]\n",
        "        bands = [cv2.imread(str(d / f\"{img_id}.tif\"), cv2.IMREAD_UNCHANGED).astype(np.float32) for d in self.band_dirs]\n",
        "        image = np.stack(bands, axis=-1)\n",
        "        label = cv2.imread(str(self.label_dir / f\"{img_id}.tif\"), cv2.IMREAD_UNCHANGED)\n",
        "        if label.ndim == 3: label = cv2.cvtColor(label, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        p02, p98 = np.percentile(image, 2), np.percentile(image, 98)\n",
        "        image = np.clip(image, p02, p98)\n",
        "        image = (image - image.min()) / (image.max() - image.min() + 1e-6)\n",
        "\n",
        "        mask = np.zeros_like(label, dtype=np.int64)\n",
        "        mask[label == 85] = 1; mask[label == 170] = 2; mask[label == 255] = 3\n",
        "\n",
        "        if self.transform:\n",
        "            aug = self.transform(image=image, mask=mask)\n",
        "            return aug[\"image\"].float(), aug[\"mask\"].long()\n",
        "        return torch.tensor(image.transpose(2,0,1)).float(), torch.tensor(mask).long()\n",
        "\n",
        "class Wrapper(Dataset):\n",
        "    def __init__(self, ds, t): self.ds, self.t = ds, t\n",
        "    def __len__(self): return len(self.ds)\n",
        "    def __getitem__(self, i):\n",
        "        img, mask = self.ds[i]\n",
        "        img = img.numpy().transpose(1,2,0); mask = mask.numpy()\n",
        "        res = self.t(image=img, mask=mask)\n",
        "        return res['image'], res['mask'].long()\n",
        "\n",
        "train_transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.5), A.RandomRotate90(p=0.5),\n",
        "    A.GridDistortion(p=0.3),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "val_transform = A.Compose([ToTensorV2()])\n",
        "\n",
        "full_ds = GlacierDataset(CONFIG['base_dir'], transform=train_transform)\n",
        "val_len = int(len(full_ds)*0.2)\n",
        "train_ds, val_ds = random_split(full_ds, [len(full_ds)-val_len, val_len], generator=torch.Generator().manual_seed(42))\n",
        "val_ds.dataset.transform = val_transform\n",
        "\n",
        "train_loader = DataLoader(Wrapper(train_ds, train_transform), batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(Wrapper(val_ds, val_transform), batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2)\n",
        "\n",
        "# ==========================================\n",
        "# 3. ARCHITECTURE: ResNet50 U-Net\n",
        "# ==========================================\n",
        "class ResNet50Encoder(nn.Module):\n",
        "    def __init__(self, mode=\"CNN\"):\n",
        "        super().__init__()\n",
        "        # Load ResNet50 (Bottleneck Architecture)\n",
        "        resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "\n",
        "        # 1. Stem\n",
        "        self.conv1 = nn.Conv2d(5, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        with torch.no_grad():\n",
        "            self.conv1.weight[:, :3] = resnet.conv1.weight\n",
        "            self.conv1.weight[:, 3:] = resnet.conv1.weight[:, :2]\n",
        "        self.bn1 = resnet.bn1\n",
        "\n",
        "        if mode == \"SNN\":\n",
        "            self.relu = snn.Leaky(beta=CONFIG['beta'], threshold=CONFIG['threshold'], spike_grad=surrogate.fast_sigmoid(slope=CONFIG['slope']), init_hidden=True)\n",
        "        else:\n",
        "            self.relu = resnet.relu\n",
        "        self.maxpool = resnet.maxpool\n",
        "\n",
        "        # 2. Layers (Bottlenecks)\n",
        "        self.layer1 = self._convert(resnet.layer1, mode)\n",
        "        self.layer2 = self._convert(resnet.layer2, mode)\n",
        "        self.layer3 = self._convert(resnet.layer3, mode)\n",
        "        self.layer4 = self._convert(resnet.layer4, mode)\n",
        "\n",
        "    def _convert(self, block, mode):\n",
        "        if mode == \"CNN\": return block\n",
        "        layers = []\n",
        "        for b in block:\n",
        "            # ResNet50 Bottleneck has ReLU in two places\n",
        "            # We replace ALL of them\n",
        "            b.relu = snn.Leaky(beta=CONFIG['beta'], threshold=CONFIG['threshold'],\n",
        "                               spike_grad=surrogate.fast_sigmoid(slope=CONFIG['slope']), init_hidden=True)\n",
        "            layers.append(b)\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = []\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        feats.append(x) # x0 (64ch, 256x256)\n",
        "\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        feats.append(x) # x1 (256ch, 128x128) - ResNet50 Expands Channels!\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        feats.append(x) # x2 (512ch, 64x64)\n",
        "\n",
        "        x = self.layer3(x)\n",
        "        feats.append(x) # x3 (1024ch, 32x32)\n",
        "\n",
        "        x = self.layer4(x)\n",
        "        feats.append(x) # x4 (2048ch, 16x16)\n",
        "\n",
        "        return feats\n",
        "\n",
        "class UnifiedDecoder(nn.Module):\n",
        "    def __init__(self, mode=\"CNN\"):\n",
        "        super().__init__()\n",
        "        spike_grad = surrogate.fast_sigmoid(slope=CONFIG['slope'])\n",
        "\n",
        "        def block(in_c, out_c):\n",
        "            act = snn.Leaky(beta=CONFIG['beta'], threshold=CONFIG['threshold'], spike_grad=spike_grad, init_hidden=True) if mode == \"SNN\" else nn.ReLU(inplace=True)\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_c, out_c, 3, padding=1),\n",
        "                nn.BatchNorm2d(out_c),\n",
        "                act\n",
        "            )\n",
        "\n",
        "        # ResNet50 Channels: [64, 256, 512, 1024, 2048]\n",
        "\n",
        "        # Up 1: 2048 -> 1024 (Connect with x3 [1024])\n",
        "        self.up4 = nn.ConvTranspose2d(2048, 1024, 2, 2)\n",
        "        self.dec4 = block(1024+1024, 1024)\n",
        "\n",
        "        # Up 2: 1024 -> 512 (Connect with x2 [512])\n",
        "        self.up3 = nn.ConvTranspose2d(1024, 512, 2, 2)\n",
        "        self.dec3 = block(512+512, 512)\n",
        "\n",
        "        # Up 3: 512 -> 256 (Connect with x1 [256])\n",
        "        self.up2 = nn.ConvTranspose2d(512, 256, 2, 2)\n",
        "        self.dec2 = block(256+256, 256)\n",
        "\n",
        "        # Up 4: 256 -> 64 (Connect with x0 [64])\n",
        "        self.up1 = nn.ConvTranspose2d(256, 64, 2, 2)\n",
        "        self.dec1 = block(64+64, 64)\n",
        "\n",
        "        # Final: 64 -> 32\n",
        "        self.final_up = nn.ConvTranspose2d(64, 32, 2, 2)\n",
        "        self.dec_final = block(32, 32)\n",
        "\n",
        "        self.final = nn.Conv2d(32, 4, 1)\n",
        "\n",
        "    def forward(self, enc_feats):\n",
        "        # x4(2048), x3(1024), x2(512), x1(256), x0(64)\n",
        "        x4, x3, x2, x1, x0 = enc_feats[4], enc_feats[3], enc_feats[2], enc_feats[1], enc_feats[0]\n",
        "\n",
        "        u4 = self.up4(x4)\n",
        "        if u4.shape != x3.shape: u4 = F.interpolate(u4, size=x3.shape[2:])\n",
        "        d4 = self.dec4(torch.cat([x3, u4], 1))\n",
        "\n",
        "        u3 = self.up3(d4)\n",
        "        if u3.shape != x2.shape: u3 = F.interpolate(u3, size=x2.shape[2:])\n",
        "        d3 = self.dec3(torch.cat([x2, u3], 1))\n",
        "\n",
        "        u2 = self.up2(d3)\n",
        "        if u2.shape != x1.shape: u2 = F.interpolate(u2, size=x1.shape[2:])\n",
        "        d2 = self.dec2(torch.cat([x1, u2], 1))\n",
        "\n",
        "        u1 = self.up1(d2)\n",
        "        if u1.shape != x0.shape: u1 = F.interpolate(u1, size=x0.shape[2:])\n",
        "        d1 = self.dec1(torch.cat([x0, u1], 1))\n",
        "\n",
        "        out = self.dec_final(self.final_up(d1))\n",
        "        return self.final(out)\n",
        "\n",
        "class UnifiedUNet(nn.Module):\n",
        "    def __init__(self, mode=\"CNN\"):\n",
        "        super().__init__()\n",
        "        self.mode = mode\n",
        "        print(f\"‚è≥ Initializing ResNet50 {mode} (Big Boss Mode)...\")\n",
        "        self.encoder = ResNet50Encoder(mode)\n",
        "        self.decoder = UnifiedDecoder(mode)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.mode == \"SNN\":\n",
        "            # No reset inside model, handled in loop\n",
        "            spk_rec = []\n",
        "            for step in range(CONFIG['time_steps']):\n",
        "                enc_feats = self.encoder(x)\n",
        "                out = self.decoder(enc_feats)\n",
        "                spk_rec.append(out)\n",
        "            return torch.stack(spk_rec).mean(0)\n",
        "        else:\n",
        "            enc_feats = self.encoder(x)\n",
        "            return self.decoder(enc_feats)\n",
        "\n",
        "# ==========================================\n",
        "# 4. TRAINING ENGINE\n",
        "# ==========================================\n",
        "def manual_reset(model):\n",
        "    for m in model.modules():\n",
        "        if hasattr(m, \"reset_mem\"): m.reset_mem()\n",
        "\n",
        "def save_vis(history, sample_vis, epoch, mode):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1,2,1); plt.plot(history['loss']); plt.title(f\"{mode} Loss\")\n",
        "    plt.subplot(1,2,2); plt.plot(history['mcc']); plt.title(f\"{mode} MCC\")\n",
        "    plt.savefig(f\"{CONFIG['project_dir']}/{mode}_history.png\"); plt.close()\n",
        "\n",
        "    img, gt, pred = sample_vis\n",
        "    rgb = img[[3,2,1]].transpose(1,2,0)\n",
        "    rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min() + 1e-6)\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 3, 1); plt.imshow(rgb); plt.title(\"Input\")\n",
        "    plt.subplot(1, 3, 2); plt.imshow(gt, cmap='nipy_spectral', interpolation='nearest'); plt.title(\"GT\")\n",
        "    plt.subplot(1, 3, 3); plt.imshow(pred, cmap='nipy_spectral', interpolation='nearest'); plt.title(f\"{mode} Pred\")\n",
        "    plt.savefig(f\"{CONFIG['project_dir']}/{mode}_sample.png\"); plt.close()\n",
        "\n",
        "def run_training():\n",
        "    model = UnifiedUNet(mode=CONFIG['model_type']).to(CONFIG['device'])\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'])\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=3e-4, steps_per_epoch=len(train_loader), epochs=CONFIG['epochs'])\n",
        "\n",
        "    weights = torch.tensor([0.2, 1.0, 1.0, 3.0]).to(CONFIG['device'])\n",
        "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    best_mcc = -1.0\n",
        "    history = {'loss': [], 'mcc': []}\n",
        "\n",
        "    for epoch in range(CONFIG['epochs']):\n",
        "        model.train()\n",
        "        run_loss = 0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"{CONFIG['model_type']} Ep {epoch+1}\")\n",
        "        for imgs, masks in loop:\n",
        "            imgs, masks = imgs.to(CONFIG['device']), masks.to(CONFIG['device'])\n",
        "\n",
        "            if CONFIG['model_type'] == \"SNN\": manual_reset(model)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if CONFIG['model_type'] == \"CNN\":\n",
        "                with autocast():\n",
        "                    out = model(imgs)\n",
        "                    loss = criterion(out, masks)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                out = model(imgs)\n",
        "                loss = criterion(out, masks)\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "            scheduler.step()\n",
        "            run_loss += loss.item()\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        # Val\n",
        "        model.eval()\n",
        "        preds, targets = [], []\n",
        "        sample_vis = None\n",
        "        with torch.no_grad():\n",
        "            for i, (imgs, masks) in enumerate(val_loader):\n",
        "                imgs = imgs.to(CONFIG['device'])\n",
        "                if CONFIG['model_type'] == \"SNN\": manual_reset(model)\n",
        "\n",
        "                if CONFIG['model_type'] == \"CNN\":\n",
        "                    with autocast(): out = model(imgs)\n",
        "                else:\n",
        "                    out = model(imgs)\n",
        "\n",
        "                preds.append(out.argmax(1).cpu())\n",
        "                targets.append(masks.cpu())\n",
        "\n",
        "                if i==0: sample_vis = (imgs[0].cpu().numpy(), masks[0].cpu().numpy(), preds[-1][0].numpy())\n",
        "\n",
        "        mcc = matthews_corrcoef(torch.cat(targets).numpy().flatten(), torch.cat(preds).numpy().flatten())\n",
        "        history['mcc'].append(mcc)\n",
        "        history['loss'].append(run_loss/len(train_loader))\n",
        "\n",
        "        print(f\"   ‚úÖ Val MCC: {mcc:.4f}\")\n",
        "        save_vis(history, sample_vis, epoch+1, CONFIG['model_type'])\n",
        "\n",
        "        if mcc > best_mcc:\n",
        "            best_mcc = mcc\n",
        "            torch.save(model.state_dict(), f\"{CONFIG['project_dir']}/best_{CONFIG['model_type']}_ResNet50.pth\")\n",
        "\n",
        "    print(f\"üèÅ {CONFIG['model_type']} Finished. Best MCC: {best_mcc:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_training()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8jMbD0n7OAlr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
