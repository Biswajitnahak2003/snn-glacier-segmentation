{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohh7I6aLsm8W",
        "outputId": "02154b84-fc01-42a7-f2ba-d1ef4ed8ab34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "## mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snntorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr4p1XwYsvx5",
        "outputId": "8ee07073-65d2-440c-a476-811a8226184b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: snntorch in /usr/local/lib/python3.12/dist-packages (0.9.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n"
      ],
      "metadata": {
        "id": "4xQqViAp4ZOw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "import gc\n",
        "\n",
        "# --- SNN Imports ---\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from snntorch import utils\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONFIGURATION (STABLE MODE)\n",
        "# ==========================================\n",
        "CONFIG = {\n",
        "    \"base_dir\": \"/content/drive/MyDrive/GlacierHack_practice/Train\",\n",
        "    \"project_dir\": \"/content/drive/MyDrive/Glacier_SNN_Project\",\n",
        "    \"model_type\": \"SNN\",\n",
        "    \"time_steps\": 4,\n",
        "    \"beta\": 0.9,\n",
        "    \"epochs\": 30,\n",
        "    \"batch_size\": 2,       # Safe for Float32\n",
        "    \"lr\": 1e-3,\n",
        "    \"num_workers\": 2,\n",
        "    \"seed\": 42,\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "}\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "os.makedirs(CONFIG['project_dir'], exist_ok=True)\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seed(CONFIG['seed'])\n",
        "\n",
        "# ==========================================\n",
        "# 2. DATASET\n",
        "# ==========================================\n",
        "class GlacierDataset(Dataset):\n",
        "    def __init__(self, base_dir, transform=None):\n",
        "        self.base_dir = Path(base_dir)\n",
        "        self.band_dirs = [self.base_dir / f\"Band{i}\" for i in range(1, 6)]\n",
        "        self.label_dir = self.base_dir / \"labels\"\n",
        "        self.ids = sorted([p.stem for p in self.band_dirs[0].glob(\"*.tif\")])\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): return len(self.ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.ids[idx]\n",
        "        bands = [cv2.imread(str(d / f\"{img_id}.tif\"), cv2.IMREAD_UNCHANGED).astype(np.float32) for d in self.band_dirs]\n",
        "        image = np.stack(bands, axis=-1)\n",
        "        label = cv2.imread(str(self.label_dir / f\"{img_id}.tif\"), cv2.IMREAD_UNCHANGED)\n",
        "        if label.ndim == 3: label = cv2.cvtColor(label, cv2.COLOR_BGR2GRAY)\n",
        "        mask = np.zeros_like(label, dtype=np.uint8)\n",
        "        mask[label == 85] = 1; mask[label == 170] = 2; mask[label == 255] = 3\n",
        "\n",
        "        p02, p98 = np.percentile(image, 2), np.percentile(image, 98)\n",
        "        image = np.clip(image, p02, p98)\n",
        "        image = (image - image.min()) / (image.max() - image.min() + 1e-6)\n",
        "\n",
        "        if self.transform:\n",
        "            aug = self.transform(image=image, mask=mask)\n",
        "            return aug[\"image\"].float(), aug[\"mask\"].long()\n",
        "        return torch.tensor(image.transpose(2,0,1)).float(), torch.tensor(mask).long()\n",
        "\n",
        "class Wrapper(Dataset):\n",
        "    def __init__(self, ds, t): self.ds, self.t = ds, t\n",
        "    def __len__(self): return len(self.ds)\n",
        "    def __getitem__(self, i):\n",
        "        img, mask = self.ds[i]\n",
        "        img = img.numpy().transpose(1,2,0); mask = mask.numpy()\n",
        "        res = self.t(image=img, mask=mask)\n",
        "        return res['image'], res['mask'].long()\n",
        "\n",
        "train_transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5), A.VerticalFlip(p=0.5), A.RandomRotate90(p=0.5),\n",
        "    A.GridDistortion(p=0.3),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "val_transform = A.Compose([ToTensorV2()])\n",
        "\n",
        "full_dataset = GlacierDataset(CONFIG['base_dir'], transform=None)\n",
        "val_len = int(len(full_dataset)*0.2)\n",
        "train_ds, val_ds = random_split(full_dataset, [len(full_dataset)-val_len, val_len])\n",
        "\n",
        "train_loader = DataLoader(Wrapper(train_ds, train_transform), batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(Wrapper(val_ds, val_transform), batch_size=CONFIG['batch_size'], shuffle=False, num_workers=2)\n",
        "\n",
        "# ==========================================\n",
        "# 3. SNN ARCHITECTURE\n",
        "# ==========================================\n",
        "class SNNBlock(nn.Module):\n",
        "    def __init__(self, in_c, out_c):\n",
        "        super().__init__()\n",
        "        spike_grad = surrogate.fast_sigmoid()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_c, out_c, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_c),\n",
        "            snn.Leaky(beta=CONFIG['beta'], spike_grad=spike_grad, init_hidden=True),\n",
        "\n",
        "            nn.Conv2d(out_c, out_c, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_c),\n",
        "            snn.Leaky(beta=CONFIG['beta'], spike_grad=spike_grad, init_hidden=True)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class ProjectUNet(nn.Module):\n",
        "    def __init__(self, in_ch=5, n_classes=4):\n",
        "        super().__init__()\n",
        "        Block = SNNBlock\n",
        "        self.inc = Block(in_ch, 32)\n",
        "        self.down1 = nn.Sequential(nn.MaxPool2d(2), Block(32, 64))\n",
        "        self.down2 = nn.Sequential(nn.MaxPool2d(2), Block(64, 128))\n",
        "        self.down3 = nn.Sequential(nn.MaxPool2d(2), Block(128, 256))\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.conv1 = Block(256, 128)\n",
        "        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.conv2 = Block(128, 64)\n",
        "        self.up3 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
        "        self.conv3 = Block(64, 32)\n",
        "        self.outc = nn.Conv2d(32, n_classes, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # MANUAL RESET inside forward is dangerous for BPTT\n",
        "        # We handle reset in the training loop instead\n",
        "\n",
        "        spk_rec = []\n",
        "        for step in range(CONFIG['time_steps']):\n",
        "            x1 = self.inc(x)\n",
        "            x2 = self.down1(x1)\n",
        "            x3 = self.down2(x2)\n",
        "            x4 = self.down3(x3)\n",
        "\n",
        "            x_up1 = self.up1(x4)\n",
        "            if x_up1.shape != x3.shape: x_up1 = F.interpolate(x_up1, size=x3.shape[2:])\n",
        "            x5 = self.conv1(torch.cat([x3, x_up1], dim=1))\n",
        "\n",
        "            x_up2 = self.up2(x5)\n",
        "            if x_up2.shape != x2.shape: x_up2 = F.interpolate(x_up2, size=x2.shape[2:])\n",
        "            x6 = self.conv2(torch.cat([x2, x_up2], dim=1))\n",
        "\n",
        "            x_up3 = self.up3(x6)\n",
        "            if x_up3.shape != x1.shape: x_up3 = F.interpolate(x_up3, size=x1.shape[2:])\n",
        "            x7 = self.conv3(torch.cat([x1, x_up3], dim=1))\n",
        "\n",
        "            out = self.outc(x7)\n",
        "            spk_rec.append(out)\n",
        "\n",
        "        return torch.stack(spk_rec).mean(0)\n",
        "\n",
        "# ==========================================\n",
        "# 4. VISUALIZATION\n",
        "# ==========================================\n",
        "def save_plot_and_sample(history, sample_data, epoch):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['loss'], label='Train Loss')\n",
        "    plt.title(\"SNN Loss\")\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['mcc'], label='Val MCC', color='green')\n",
        "    plt.title(\"SNN MCC\")\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"{CONFIG['project_dir']}/SNN_metrics.png\")\n",
        "    plt.close()\n",
        "\n",
        "    img, gt, pred = sample_data\n",
        "    rgb = img[[3,2,1]].transpose(1,2,0)\n",
        "    rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min() + 1e-6)\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 3, 1); plt.imshow(rgb); plt.title(\"Input\")\n",
        "    plt.subplot(1, 3, 2); plt.imshow(gt, cmap='nipy_spectral'); plt.title(\"Ground Truth\")\n",
        "    plt.subplot(1, 3, 3); plt.imshow(pred, cmap='nipy_spectral'); plt.title(f\"Pred (Ep {epoch})\")\n",
        "    plt.savefig(f\"{CONFIG['project_dir']}/SNN_sample.png\")\n",
        "    plt.close()\n",
        "\n",
        "# ==========================================\n",
        "# 5. TRAINING\n",
        "# ==========================================\n",
        "def manual_reset(model):\n",
        "    \"\"\"Force reset all spiking layers\"\"\"\n",
        "    for m in model.modules():\n",
        "        if hasattr(m, \"reset_mem\"):\n",
        "            m.reset_mem()\n",
        "\n",
        "print(\"ğŸš€ Initializing SNN U-Net...\")\n",
        "model = ProjectUNet(in_ch=5, n_classes=4).to(CONFIG['device'])\n",
        "optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# REMOVED SCALER (NO AMP)\n",
        "\n",
        "best_mcc = -1.0\n",
        "history = {'loss': [], 'mcc': []}\n",
        "\n",
        "print(f\"ğŸ”¥ Starting SNN Training (BS={CONFIG['batch_size']}, Float32)...\")\n",
        "\n",
        "for epoch in range(CONFIG['epochs']):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Ep {epoch+1}\")\n",
        "    for imgs, masks in pbar:\n",
        "        imgs, masks = imgs.to(CONFIG['device']), masks.to(CONFIG['device']).long()\n",
        "\n",
        "        # 1. Manual Reset (Critical)\n",
        "        manual_reset(model)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 2. Standard Forward/Backward (No Autocast)\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, masks)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    history['loss'].append(avg_loss)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "    sample_vis = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (imgs, masks) in enumerate(val_loader):\n",
        "            imgs = imgs.to(CONFIG['device'])\n",
        "\n",
        "            manual_reset(model) # Reset before inference too!\n",
        "            out = model(imgs)\n",
        "\n",
        "            p = out.argmax(1).cpu()\n",
        "            preds.append(p)\n",
        "            targets.append(masks.cpu())\n",
        "\n",
        "            if i == 0:\n",
        "                sample_vis = (imgs[0].cpu().numpy(), masks[0].cpu().numpy(), p[0].numpy())\n",
        "\n",
        "    mcc = matthews_corrcoef(torch.cat(targets).numpy().flatten(), torch.cat(preds).numpy().flatten())\n",
        "    history['mcc'].append(mcc)\n",
        "\n",
        "    print(f\"Ep {epoch+1} | Loss: {avg_loss:.4f} | Val MCC: {mcc:.4f}\")\n",
        "\n",
        "    save_plot_and_sample(history, sample_vis, epoch+1)\n",
        "\n",
        "    if mcc > best_mcc:\n",
        "        best_mcc = mcc\n",
        "        torch.save(model.state_dict(), f\"{CONFIG['project_dir']}/best_SNN.pth\")\n",
        "        print(\"âœ… Saved Best SNN Model!\")\n",
        "\n",
        "print(f\"ğŸ Training Complete. Best MCC: {best_mcc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lych7SJbsvur",
        "outputId": "1fe3380c-0adc-48d4-8a19-2086dcc2ba64"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Initializing SNN U-Net...\n",
            "ğŸ”¥ Starting SNN Training (BS=2, Float32)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:10<00:00,  1.05s/it, loss=1.16]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 | Loss: 1.2273 | Val MCC: 0.2803\n",
            "âœ… Saved Best SNN Model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.11it/s, loss=0.943]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 2 | Loss: 1.0311 | Val MCC: 0.3838\n",
            "âœ… Saved Best SNN Model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.12it/s, loss=0.936]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 3 | Loss: 0.9292 | Val MCC: 0.4266\n",
            "âœ… Saved Best SNN Model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s, loss=0.919]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 4 | Loss: 0.8526 | Val MCC: 0.4158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s, loss=0.808]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 5 | Loss: 0.7970 | Val MCC: 0.3689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.14it/s, loss=0.825]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 6 | Loss: 0.7465 | Val MCC: 0.4183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s, loss=0.663]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 7 | Loss: 0.7132 | Val MCC: 0.4709\n",
            "âœ… Saved Best SNN Model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.11it/s, loss=0.635]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 8 | Loss: 0.6890 | Val MCC: 0.4655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.14it/s, loss=0.596]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 9 | Loss: 0.6485 | Val MCC: 0.4588\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.14it/s, loss=0.695]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 10 | Loss: 0.6379 | Val MCC: 0.4945\n",
            "âœ… Saved Best SNN Model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s, loss=0.584]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 11 | Loss: 0.6252 | Val MCC: 0.4926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s, loss=0.621]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 12 | Loss: 0.6397 | Val MCC: 0.4857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.11it/s, loss=0.523]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 13 | Loss: 0.6125 | Val MCC: 0.4251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.12it/s, loss=0.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 14 | Loss: 0.5985 | Val MCC: 0.4169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.14it/s, loss=0.621]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 15 | Loss: 0.5996 | Val MCC: 0.4625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s, loss=0.713]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 16 | Loss: 0.5889 | Val MCC: 0.4860\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.14it/s, loss=0.52]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 17 | Loss: 0.5810 | Val MCC: 0.4986\n",
            "âœ… Saved Best SNN Model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s, loss=0.494]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 18 | Loss: 0.5798 | Val MCC: 0.4713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.09it/s, loss=0.452]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 19 | Loss: 0.5689 | Val MCC: 0.4829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.14it/s, loss=0.642]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 20 | Loss: 0.5473 | Val MCC: 0.4878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s, loss=0.378]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 21 | Loss: 0.5515 | Val MCC: 0.5075\n",
            "âœ… Saved Best SNN Model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s, loss=0.518]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 22 | Loss: 0.5582 | Val MCC: 0.5223\n",
            "âœ… Saved Best SNN Model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s, loss=0.581]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 23 | Loss: 0.5570 | Val MCC: 0.4811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s, loss=0.433]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 24 | Loss: 0.5362 | Val MCC: 0.4995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.12it/s, loss=0.578]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 25 | Loss: 0.5420 | Val MCC: 0.5104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s, loss=0.639]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 26 | Loss: 0.5388 | Val MCC: 0.5233\n",
            "âœ… Saved Best SNN Model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s, loss=0.683]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 27 | Loss: 0.5407 | Val MCC: 0.5121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.13it/s, loss=0.447]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 28 | Loss: 0.5470 | Val MCC: 0.4611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.14it/s, loss=0.401]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 29 | Loss: 0.5434 | Val MCC: 0.4926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.06it/s, loss=0.557]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 30 | Loss: 0.5280 | Val MCC: 0.4967\n",
            "ğŸ Training Complete. Best MCC: 0.5233\n"
          ]
        }
      ]
    }
  ]
}